{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04549ac",
   "metadata": {},
   "source": [
    "## Types of Query Construction\n",
    "\n",
    "- **Vector Databases**  \n",
    "  Queries are primarily based on vector similarity, often using embeddings and nearest neighbor search.\n",
    "\n",
    "- **Graph Databases**  \n",
    "  Queries are constructed to traverse nodes and edges, focusing on relationships and connections between entities.\n",
    "\n",
    "- **Relational Databases**  \n",
    "  Queries are built using SQL or similar query languages to retrieve structured data based on tables, rows, and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first get path where sqlite database will store\n",
    "# for now i am using docker for sqlite using below command and make one db\n",
    "# docker run -it --name python_sqlite -v /c/Users/aniln/Desktop/github_celery_redis/Advance_RAG2:/app/data python:3.11-slim bash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc79f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['employees']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# Connect to SQLite database (or create it if it doesn't exist)\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create a new table\n",
    "cur.execute('''\n",
    "CREATE TABLE IF NOT EXISTS employees (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    age INTEGER,\n",
    "    department TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "cur.execute(\"INSERT INTO employees (name, age, department) VALUES ('Alice', 30, 'HR')\")\n",
    "cur.execute(\"INSERT INTO employees (name, age, department) VALUES ('Bob', 24, 'Engineering')\")\n",
    "cur.execute(\"INSERT INTO employees (name, age, department) VALUES ('Charlie', 28, 'Marketing')\")\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///example.db\")\n",
    "\n",
    "# Print the database dialect\n",
    "print(db.dialect)\n",
    "\n",
    "# Print usable table names\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d527b3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL: SELECT COUNT(*) FROM employees;\n",
      "Result: [(6,)]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# Connect to your SQLite database\n",
    "db = SQLDatabase.from_uri(\"sqlite:///example.db\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Replace with your key\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "\n",
    "# Initialize OpenAI chat model\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4\",  # or \"gpt-3.5-turbo\"\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Define prompt for SQL generation\n",
    "system_message = \"You are a helpful assistant. Your job is to convert natural language questions to SQL queries. Only give the SQL query.\"\n",
    "human_message = \"{question}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    (\"human\", human_message)\n",
    "])\n",
    "\n",
    "# Create chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Example query\n",
    "response = chain.invoke({\"question\": \"How many employees are there?\"})\n",
    "sql_query = response.content\n",
    "print(\"Generated SQL:\", sql_query)\n",
    "\n",
    "# Run the SQL on database\n",
    "result = db.run(sql_query)\n",
    "print(\"Result:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5bd2b",
   "metadata": {},
   "source": [
    "## Vecotr DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58825d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# pip install langchain chromadb unstructured openai\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# 1️⃣ Load documents from folder\n",
    "directory = \"C:/Users/aniln/Desktop/github_celery_redis/Advance_RAG2/documents/\"  # Replace with your folder path\n",
    "loader = DirectoryLoader(directory, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "\n",
    "# 2️⃣ Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3️⃣ Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 4️⃣ Create vector database and persist locally\n",
    "persist_directory = \"local_vector_db\"\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102e470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I'm sorry, but your question about cricket is not clear. Could you please provide more details or context?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5️⃣ Create retriever\n",
    "vectorstore_retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# 6️⃣ Initialize OpenAI LLM\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4\",  # or \"gpt-3.5-turbo\"\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 7️⃣ Combine retriever and LLM in a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore_retriever,\n",
    "    return_source_documents=False  # <-- only one output key\n",
    ")\n",
    "\n",
    "# 8️⃣ Prompt user query\n",
    "warning = \"Please refrain from speculating if unsure. Simply state 'I don't know'. Keep answers concise (~200 words).\"\n",
    "user_query = input(\"Enter your query: \")\n",
    "query = warning + \" Requirement: \" + user_query\n",
    "\n",
    "# 9️⃣ Get answer\n",
    "llm_response = qa_chain.run(query)\n",
    "print(\"Response:\", llm_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "channel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
