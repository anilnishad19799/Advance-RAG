{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9380e7fd",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Indexing Techniques\n",
    "\n",
    "- **K-Nearest Neighbours (KNN)**\n",
    "- **Inverted File Vector**\n",
    "- **Locality Sensitive Hashing (LSH)**\n",
    "- **Random Projection**\n",
    "- **Product Quantization**\n",
    "- **Hierarchical Navigable Small World (HNSW)**\n",
    "- **Hierarchical Indexing**\n",
    "- **Multi-Representation Indexing**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8a4a8",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Popular Vector/Embedding Databases\n",
    "\n",
    "- **ChromaDB** â€“ Lightweight, open-source vector database for embeddings.  \n",
    "- **Milvus** â€“ High-performance, scalable vector database for similarity search.  \n",
    "- **Pinecone** â€“ Managed vector database for real-time AI applications.  \n",
    "- **Weaviate** â€“ Cloud-native vector search engine with semantic search capabilities.  \n",
    "- **FAISS (Facebook AI Similarity Search)** â€“ Library for efficient similarity search and clustering of dense vectors.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285dfd8",
   "metadata": {},
   "source": [
    "## Storing Data in Vector Databases\n",
    "\n",
    "In this section, we will demonstrate how to store data in various vector databases.  \n",
    "Each database uses a specific indexing technique optimized for efficient similarity search.\n",
    "\n",
    "- **ChromaDB** â€“ Uses **Hierarchical Navigable Small World (HNSW)** indexing for fast and scalable approximate nearest neighbor searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848ef697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"rag_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"Medical_collection\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f35f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c8da5918-389d-4a75-ac71-c1562c5ff36d',\n",
       " '51d232b8-6f47-4055-ba23-a4ccdbff1eec',\n",
       " '7c85a091-f7f8-4fe3-8b50-961176937a13',\n",
       " '60d8120b-395b-4eaa-8905-fc75112decd7',\n",
       " '64d7cb52-f78d-4a38-bbdc-93cc810b42b6',\n",
       " 'd08a8ac2-b2bb-4980-8451-1c90bc800866',\n",
       " 'e92a5019-5d5d-48f0-814e-c60b64f0f901',\n",
       " '1e04c24b-007f-485a-a929-10a6f083e6a2',\n",
       " '2c7801c4-67c7-44fa-8dba-effe3cdd6fab',\n",
       " 'efc907f4-356a-410f-909d-b35234028ea9']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c7bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357a3d3",
   "metadata": {},
   "source": [
    "## Faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdbbe1c",
   "metadata": {},
   "source": [
    "- **FAISS (Facebook AI Similarity Search)** â€“ Provides several indexing options for efficient vector search:  \n",
    "  - **Flat (brute-force)** â€“ exact search  \n",
    "  - **IVF (Inverted File)** â€“ partitions vectors for faster approximate search  \n",
    "  - **HNSW (Hierarchical Navigable Small World)** â€“ graph-based ANN search  \n",
    "  - **PQ (Product Quantization)** â€“ compresses vectors for memory-efficient search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55efdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1710960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55819bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2358ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['80fc960a-40a6-4e88-8d1c-39aa790703d2',\n",
       " '290662ee-5e1b-4ba2-aa01-f9e01d0a176a',\n",
       " '62328396-3fdf-462a-8d5f-ce72455a7a84',\n",
       " 'ba85a075-4d2b-4b50-b870-454ff9001aab',\n",
       " 'b3e88468-a9dc-4ee5-86b9-1d60274b8569',\n",
       " 'a5fb7453-ac62-4e44-bd62-8abcb86e7d97',\n",
       " '53036063-ce25-4172-8236-7d7c5f2dddb7',\n",
       " '49330dcc-8eab-4098-b255-abf98c2fce30',\n",
       " '17f2b192-4e8d-433c-a104-7a37d8cdefd3',\n",
       " 'fe62e242-aefd-4cff-96ec-80279f3c1503']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c57a2430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573a9af",
   "metadata": {},
   "source": [
    "## PineCone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa0e87",
   "metadata": {},
   "source": [
    "- **Pinecone Indexing Techniques**:  \n",
    "  - **HNSW (Hierarchical Navigable Small World)** â€“ Graph-based approximate nearest neighbor search.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6964c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "010cf6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aniln\\miniconda3\\envs\\channel\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"testing\"  # change if desired\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4072638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aniln\\miniconda3\\envs\\channel\\Lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85134e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8c8fa098-c342-4367-adad-a955359b054e',\n",
       " '36084bf9-6e61-4058-a8b2-44038e1a70da',\n",
       " '8a831902-d44f-4e12-aeee-c9308fc29ba1',\n",
       " '25e0d899-b32a-4321-91e2-12f26c6e2fbd',\n",
       " '7101551a-aae7-410f-86fe-6503dcb64edb',\n",
       " 'f83d3243-c84d-4a99-92e5-127744c32838',\n",
       " 'ce866965-2ee0-4f71-8f76-4897c9dac834',\n",
       " '92566a1e-ad8b-448b-bb14-f0aa0f8f2ce1',\n",
       " 'fa2edc94-be21-423c-bbf5-44657a485f8d',\n",
       " '135487b0-a514-41cd-b991-58bdaf432197']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71f8f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* I have a bad feeling I am going to get deleted :( [{'source': 'tweet'}]\n",
      "* I had chocolate chip pancakes and scrambled eggs for breakfast this morning. [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"Will it be hot tomorrow?\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600940b8",
   "metadata": {},
   "source": [
    "## Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfad06f",
   "metadata": {},
   "source": [
    "- **Milvus**:  \n",
    "  - **HNSW (Hierarchical Navigable Small World)** â€“ Graph-based approximate nearest neighbor search.  \n",
    "  - **IVF (Inverted File)** â€“ Clusters vectors for efficient search within relevant partitions.  \n",
    "  - **IVF-PQ (Inverted File with Product Quantization)** â€“ Combines IVF with compression for memory-efficient search.  \n",
    "  - **FLAT** â€“ Brute-force exact search (accurate but slower for large datasets).  \n",
    "  - **ScaNN (Scalable Nearest Neighbors)** â€“ Optimized high-dimensional vector search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb36c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For runnnug milvus we have to do certain step to run milvus database\n",
    "\n",
    "# step 1 - docker start\n",
    "# step 2 - run command given below\n",
    "# docker pull milvusdb/milvus:v2.0.0\n",
    "# docker run -d --name milvus_cpu_2.0.0 -p 19530:19530 -p 19121:19121 milvusdb/milvus:v2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85107734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f439a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_milvus import Milvus\n",
    "\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    "    index_params={\"index_type\": \"FLAT\", \"metric_type\": \"L2\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    expr='source == \"tweet\"',\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2736d",
   "metadata": {},
   "source": [
    "## Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe5efc",
   "metadata": {},
   "source": [
    "- **Weaviate Indexing Techniques**:\n",
    "  - **HNSW (Hierarchical Navigable Small World)** â€“ Primary indexing method for approximate nearest neighbor search.\n",
    "  - **Hybrid Search** â€“ Combines vector search with filters or keyword-based search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c465ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For runnnug milvus we have to do certain step to run weavite database\n",
    "\n",
    "# Give path in last command\n",
    "# step 1 - docker start\n",
    "# step 2 - run command given below\n",
    "# docker pull semitechnologies/weaviate:latest    \n",
    "# docker run -d --name weaviate_local -p 8080:8080 -p 50051:50051 -e QUERY_DEFAULTS_LIMIT=20 -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true -e PERSISTENCE_DATA_PATH=\"Give own path\" semitechnologies/weaviate:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ad7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "weaviate_client = weaviate.connect_to_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d38b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "loader = TextLoader(\"sample.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "db = WeaviateVectorStore.from_documents(docs, embeddings, client=weaviate_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec0ae6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "Key Characteristics of Transformers:\n",
      "Self-Attention Mechanism: The self-attention mechanism allows T...\n",
      "\n",
      "Document 2:\n",
      "What Are Transformers?\n",
      "Transformers are a type of neural network architecture that has revolutionize...\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain LLMs\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "# Print the first 100 characters of each result\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nDocument {i + 1}:\")\n",
    "    print(doc.page_content[:100] + \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "channel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
